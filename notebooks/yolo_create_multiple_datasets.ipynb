{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# BLANK\n",
    "import torch\n",
    "from torch import cuda\n",
    "\n",
    "import os\n",
    "import shutil\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from tqdm.auto import tqdm, trange\n",
    "from importlib import reload\n",
    "\n",
    "# Clone FTCNN repo here: https://www.github.com/joeletho/FTCNN.git\n",
    "\n",
<<<<<<< Updated upstream:notebooks/YOLO-FTCNN-CreateAllDatasets.ipynb
    "# Directory of cloned repo\n",
    "sys.path.append(CHANGE_ME)\n",
=======
    "# Cloned repo directory\n",
    "sys.path.append(\"path/to/ftcnn\")\n",
>>>>>>> Stashed changes:notebooks/yolo_create_multiple_datasets.ipynb
    "\n",
    "import ftcnn\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLANK\n",
    "print(sys.version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLANK\n",
    "print(reload(ftcnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLANK\n",
    "has_gpu = cuda.is_available()\n",
    "\n",
    "device = torch.device('cuda' if has_gpu else 'cpu')\n",
    "print(device)\n",
    "if has_gpu:\n",
    "    print(cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### Example directory structure:\n",
    "```\n",
    "Root\n",
    "  ├── FTCNN_YOLO\n",
    "  |         ├── datasets\n",
    "  |         ├── models\n",
    "  ├── NDVI\n",
    "  ├── QGIS\n",
    "  ├── Readme.txt\n",
    "  ├── Shapefiles\n",
    "  ...\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLANK\n",
    "path_map = {}\n",
    "\n",
    "# Change this to your project path\n",
    "path_map['ROOT'] = Path(\"path/to/project/root\")\n",
    "\n",
    "path_map['PROJECT_NAME'] = 'FTCNN_YOLO'\n",
    "path_map['FTCNN'] = path_map['ROOT'] / path_map[\"PROJECT_NAME\"]\n",
    "path_map['FTCNN_DS'] = path_map['FTCNN'] / 'datasets'\n",
    "path_map['FTCNN_MODELS'] = path_map['FTCNN'] / 'models'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLANK\n",
    "def make_directories(paths_map, verbose=True, exist_ok=False):\n",
    "    if verbose:\n",
    "        print(\"Creating directory structure\")\n",
    "    for name, path in paths_map.items():\n",
    "        if isinstance(path, Path):\n",
    "            if path.is_file() or len(path.suffix) > 0:\n",
    "                paths_map[name] = path.resolve()\n",
    "            else:\n",
    "                path = path.resolve()\n",
    "                paths_map[name] = path\n",
    "                path.mkdir(parents=True, exist_ok=exist_ok)\n",
    "                if verbose:\n",
    "                    print('  ',path)\n",
    "    if verbose:\n",
    "        print(\"Complete\")\n",
    "\n",
    "def make_project_paths(root,*, verbose=True, exist_ok=False):    \n",
    "    paths = {'NDVI': Path(root, 'NDVI', 'NDVI Difference Rasters')}\n",
    "    paths['SHAPE_FILES'] = Path(root, 'Shapefiles')\n",
    "\n",
    "    paths['FTCNN_DS_META'] = path_map['FTCNN_DS'] / 'meta'\n",
    "    paths['FTCNN_DS_CSV'] = paths['FTCNN_DS_META'] / 'csv'\n",
    "    paths['FTCNN_DS_SHP'] = paths['FTCNN_DS_META'] / 'shp'\n",
    "    \n",
    "    # Data\n",
    "    paths['PRED_SHP'] = paths['SHAPE_FILES'] / 'ModelPredictions'\n",
    "    paths['SHPZ10_SHP'] = paths['SHAPE_FILES'] / 'Treatments_UTMz10_Only_08-18-24' / 'Treatments_UTMz10_Only_08-18-24.shp'\n",
    "    paths['SHPZ11_SHP'] = paths['SHAPE_FILES'] / 'Treatments_UTMz11_Only_08-18-24' / 'Treatments_UTMz11_Only_08-18-24.shp'\n",
    "    for name, path in paths.items():\n",
    "        path_map[name] = path\n",
    "    make_directories(paths, verbose=verbose, exist_ok=exist_ok)\n",
    "\n",
    "        \n",
    "def make_dataset_paths(ds_root, models_root, model_name, *,verbose=True, exist_ok=False):\n",
    "    ds_root = Path(ds_root)\n",
    "    models_root = Path(models_root)\n",
    "    paths = {}\n",
    "        \n",
    "    paths['MODEL_NAME'] = model_name\n",
    "    paths['FTCNN_MODEL'] = models_root / paths['MODEL_NAME']\n",
    "    paths['FTCNN_DS_MODEL'] = ds_root / paths['MODEL_NAME']\n",
    "    paths['FTCNN_DS_MODEL_META'] = paths['FTCNN_DS_MODEL'] / 'meta'\n",
    "    paths['FTCNN_DS_MODEL_SHP'] = paths['FTCNN_DS_MODEL_META'] / 'shp'\n",
    "    paths['FTCNN_DS_MODEL_CSV'] = paths['FTCNN_DS_MODEL_META'] / 'csv'\n",
    "    \n",
    "    paths['FTCNN_DS_DATA'] = paths['FTCNN_DS_MODEL'] / 'meta'\n",
    "    paths['FTCNN_DS_CONFIG_FILE'] = paths['FTCNN_DS_MODEL'] / 'config' / 'data.yaml'\n",
    "    paths['FTCNN_DS_YOLO_DATA_FILE'] = paths['FTCNN_DS_DATA'] / 'yolo_ndvi_ds.csv'\n",
    "    \n",
    "    # Images and labels\n",
    "    paths['FTCNN_DS_IMAGES'] = paths['FTCNN_DS_MODEL'] / 'images'\n",
    "    paths['FTCNN_DS_LABELS'] = paths['FTCNN_DS_MODEL'] / 'labels'\n",
    "    paths['FTCNN_DS_LABELS_GENERATED'] = paths['FTCNN_DS_LABELS'] / 'generated'\n",
    "    \n",
    "    paths['FTCNN_DS_CHIPS'] = paths[\"FTCNN_DS_IMAGES\"] / 'chips'\n",
    "    paths['FTCNN_DS_PNGS'] = paths[\"FTCNN_DS_IMAGES\"] / 'png'\n",
    "    paths['FTCNN_DS_TIFS'] = paths[\"FTCNN_DS_IMAGES\"] / 'tif'\n",
    "    \n",
    "    paths['FTCNN_DS_IMAGES_TRAIN'] = paths['FTCNN_DS_IMAGES'] / 'train'\n",
    "    paths['FTCNN_DS_IMAGES_TEST'] = paths['FTCNN_DS_IMAGES'] / 'test'\n",
    "    paths['FTCNN_DS_IMAGES_VAL'] = paths['FTCNN_DS_IMAGES'] / 'val'\n",
    "    \n",
    "    paths['FTCNN_DS_LABELS_TRAIN'] = paths['FTCNN_DS_LABELS'] / 'train'\n",
    "    paths['FTCNN_DS_LABELS_TEST'] = paths['FTCNN_DS_LABELS'] / 'test'\n",
    "    paths['FTCNN_DS_LABELS_VAL'] = paths['FTCNN_DS_LABELS'] / 'val'\n",
    "\n",
    "    # Metadata\n",
    "\n",
    "    # Zone 10\n",
    "    paths['CSVZ10'] = paths['FTCNN_DS_MODEL_CSV'] / 'Treatments_UTMz10.csv'\n",
    "    paths['CSVZ10_NORM'] = paths['FTCNN_DS_MODEL_CSV'] / 'Treatments_UTMz10_normalized.csv'\n",
    "    paths['CSVZ10_CLEANED'] = paths['FTCNN_DS_MODEL_CSV'] / 'Treatments_UTMz10_normalized_cleaned.csv'\n",
    "    paths['CSVZ10_CHIPPED'] = paths['FTCNN_DS_MODEL_CSV'] / 'Treatments_UTMz10_normalized_chipped.csv'\n",
    "    paths['CSVZ10_CHIP_LABELS_UTM'] = paths['FTCNN_DS_MODEL_CSV'] / 'Treatments_z10utm_chip_labels.csv'\n",
    "    paths['CSVZ10_CHIP_LABELS_PIXEL'] = paths['FTCNN_DS_MODEL_CSV'] / 'Treatments_z10pixel_chip_labels.csv'\n",
    "    paths['CSVZ10_CHIP_LABELS_PIXEL_ENCODED'] = paths['FTCNN_DS_MODEL_CSV'] / 'Treatments_z10pixel_chip_labels_encoded.csv'\n",
    "    paths['CSVZ10_CHIP_LABELS_PREYOLO'] = paths['FTCNN_DS_MODEL_CSV'] / 'Treatments_z10pixel_chip_labels_encoded_preyolo.csv'\n",
    "    \n",
    "    # Zone 11\n",
    "    paths['CSVZ11'] = paths['FTCNN_DS_MODEL_CSV'] / 'Treatments_UTMz11.csv'\n",
    "    paths['CSVZ11_NORM'] = paths['FTCNN_DS_MODEL_CSV'] / 'Treatments_UTMz11_normalized.csv'\n",
    "    paths['CSVZ11_CLEANED'] = paths['FTCNN_DS_MODEL_CSV'] / 'Treatments_UTMz11_normalized_cleaned.csv'\n",
    "    paths['CSVZ11_CHIPPED'] = paths['FTCNN_DS_MODEL_CSV'] / 'Treatments_UTMz11_normalized_chipped.csv'\n",
    "    paths['CSVZ11_CHIP_LABELS_UTM'] = paths['FTCNN_DS_MODEL_CSV'] / 'Treatments_z11utm_chip_labels.csv'\n",
    "    paths['CSVZ11_CHIP_LABELS_PIXEL'] = paths['FTCNN_DS_MODEL_CSV'] / 'Treatments_z11pixel_chip_labels.csv'\n",
    "    paths['CSVZ11_CHIP_LABELS_PIXEL_ENCODED'] = paths['FTCNN_DS_MODEL_CSV'] / 'Treatments_z11pixel_chip_labels_encoded.csv'\n",
    "    paths['CSVZ11_CHIP_LABELS_PREYOLO'] = paths['FTCNN_DS_MODEL_CSV'] / 'Treatments_z11pixel_chip_labels_encoded_preyolo.csv'\n",
    "\n",
    "    for name, path in paths.items():\n",
    "        path_map[name] = path\n",
    "    \n",
    "    make_directories(paths, verbose=verbose, exist_ok=exist_ok)\n",
    "\n",
    "    path_map['SHPZ10_PRED_SHP'] = path_map['PRED_SHP'] / f\"Treatmentsz10_{paths['MODEL_NAME']}.shp\"\n",
    "    path_map['SHPZ11_PRED_SHP'] = path_map['PRED_SHP'] / f\"Treatmentsz11_{paths['MODEL_NAME']}.shp\"\n",
    "\n",
    "make_project_paths(path_map['ROOT'], exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLANK\n",
    "def encode_classes(row):\n",
    "    geom = row.get('geometry')\n",
    "    return (0, \"Treatment\") if geom is not None and not geom.is_empty and geom.area > 1 else (-1, \"Background\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Dataset configuration settings\n",
    "IMG_SIZE = [320,640]\n",
    "\n",
    "# Ranges of years\n",
    "# YEARS=[2019, 2020, 2021, 2022, 2023]\n",
    "\n",
    "# All years\n",
    "YEARS=[None, None]\n",
    "\n",
    "SPLIT=0.75\n",
    "SPLIT_MODE=['all', 'collection']\n",
    "BACKGROUND_BIAS=[None, 1.0]\n",
    "SHUFFLE_SPLIT=[False, True]\n",
    "SHUFFLE_BACKGROUND=True\n",
    "TREATMENTS = [6]\n",
    "\n",
    "# Error list\n",
    "errors = []\n",
    "\n",
    "# Configure TQDM progress bar\n",
    "total_updates = (\n",
    "    len(TREATMENTS) *\n",
    "    (len(YEARS)-1) *\n",
    "    len(SPLIT_MODE) *\n",
    "    len(SHUFFLE_SPLIT) *\n",
    "    len(IMG_SIZE) *\n",
    "    len(BACKGROUND_BIAS)\n",
    "    )\n",
    "root_pbar = trange(total_updates)\n",
    "updates = 0\n",
    "\n",
    "# Get chip size\n",
    "for size in IMG_SIZE:\n",
    "    # Get treatment\n",
    "    for treatment in TREATMENTS: \n",
    "        # Get years\n",
    "        for i in range(len(YEARS)-1):\n",
    "            years = (YEARS[i], YEARS[i+1])\n",
    "            years = None if years is None or years[0] is None else years\n",
    "            \n",
    "            # Get split mode\n",
    "            for mode in SPLIT_MODE:\n",
    "                # Get split flag\n",
    "                for shuffle_split in SHUFFLE_SPLIT:\n",
    "                    # Get thenum_channels, old_heig background bias\n",
    "                    for background in BACKGROUND_BIAS:\n",
    "                        years_str = f\"{str(years) if years is None else f'{str(years[0])},{str(years[1])}'}\"\n",
    "                        \n",
    "                        # Update pbar message\n",
    "                        model_info = f\"T: {'all' if treatment == 0 else str(treatment)}, Y: {years_str}, SM: {mode}, S: {SPLIT}, SS: {shuffle_split}, B: {str(background)}, SB: {SHUFFLE_BACKGROUND}\"\n",
    "                        root_pbar.set_description(f\"Creating dataset {updates+1}: {model_info}\")\n",
    "        \n",
    "                        # Create the model name and create its repository\n",
    "                        path_map['MODEL_NAME'] = f\"yolo_treatments={'all' if treatment == 0 else str(treatment)}_years={years_str}_imgsz={size if size is not None else 'Default'}_split={int(SPLIT*100)}_mode={mode}_shuffle-split={shuffle_split}_bg={str(background).replace('.','_')}{'' if not SHUFFLE_BACKGROUND else '_shuffle-bg=True'}\"\n",
    "                        make_dataset_paths(\n",
    "                            path_map['FTCNN_DS'], \n",
    "                            path_map['FTCNN_MODELS'],  \n",
    "                            path_map['MODEL_NAME'], \n",
    "                            verbose=False, \n",
    "                            exist_ok=True\n",
    "                        )\n",
    "        \n",
    "                        # Load the master shapefile\n",
    "                        shpz10 = ftcnn.io.load_shapefile(path_map['SHPZ10_SHP'])\n",
    "                        if treatment == 0:\n",
    "                            # All treatments\n",
    "                            shpz10 = shpz10[shpz10['TreatmentT'] != 8]\n",
    "                        else:\n",
    "                            # Individual treatment\n",
    "                            shpz10 = shpz10[shpz10['TreatmentT'] == treatment]\n",
    "        \n",
    "                        # Rename these rows to align filenames that are parsed later\n",
    "                        shpz10.loc[shpz10['Subregion'] == \"Humboldt\", \"Subregion\"] = 'Humboldt4'\n",
    "                        if years is not None:\n",
    "                            shpz10 = shpz10[shpz10['StartYear'] == years[0]]\n",
    "                            shpz10 = shpz10[shpz10['EndYear'] == years[1]]\n",
    "        \n",
    "                        # Declare the path of the base files used for this dataset\n",
    "                        BASE_FILEPATH = Path(f'base_years={years_str}', 'Treatments_UTMz10_Only_08-18-24')\n",
    "                        \n",
    "                        # Save the files\n",
    "                        ftcnn.io.save_as_csv(shpz10, path_map['FTCNN_DS_CSV'] / BASE_FILEPATH.with_suffix('.csv'), exist_ok=True)\n",
    "                        ftcnn.io.save_as_shp(shpz10, path_map['FTCNN_DS_SHP'] / BASE_FILEPATH.with_suffix('.shp'), exist_ok=True)\n",
    "\n",
    "                        try:\n",
    "                            # Make the dataset using the base shapefile\n",
    "                            yolo_ds,_ = ftcnn.modeling.yolo.ndvi_to_yolo_dataset(\n",
    "                                shp_file=(\n",
    "                                    path_map['FTCNN_DS_SHP'] / BASE_FILEPATH.with_suffix('.shp') \n",
    "                                         ),                              # shapefile\n",
    "                                ndvi_dir=path_map['NDVI'],               # directory containing all NDVI images\n",
    "                                output_dir=path_map['FTCNN_DS_MODEL'],   # destination\n",
    "                                id_column=\"Subregion\",                   # parse images by\n",
    "                                start_year_col=\"StartYear\",              # starting with year\n",
    "                                end_year_col=\"EndYear\",                  # and ending with year\n",
    "                                years=years,                             # years range\n",
    "                                chip_size=size,                          # size of created chips\n",
    "                                clean_dest=True,                         # remove existing files\n",
    "                                xy_to_index=True,                        # translate spacial coords to pixel\n",
    "                                tif_to_png=True,                         # also make PNGs of all chips\n",
    "                                split_mode=mode,                         # choose between \"all\" or \"collection\" to split chips by all images or by each image\n",
    "                                split=SPLIT,                             # factor to split dataset (default 0.75)\n",
    "                                shuffle_split=shuffle_split,             # shuffle dataset\n",
    "                                shuffle_background=SHUFFLE_BACKGROUND,   # only used if `background_bias` is used\n",
    "                                background_bias=background,              # factor of background labels\n",
    "                                encoder=encode_classes,                  # custom class encoder \n",
    "                                generate_train_data=True,                # generate labels and config files, etc\n",
    "                                pbar_leave=False,                        # pbar option\n",
    "                                ignore_empty_geom=True,\n",
    "                                exist_ok=True,\n",
    "                                save_csv=True,\n",
    "                                save_shp=True,\n",
    "                            )\n",
    "        \n",
    "                            if len(yolo_ds.images) < 20:\n",
    "                                # If the size is too small the dataset encounters issues so we limit it to a \n",
    "                                # size that may provide a decent number of images for training\n",
    "                                raise ValueError(\"Too few images to be viable dataset\")\n",
    "        \n",
    "                            # (Optional) Change the root path of the dataset to the target directory where it will be used later on\n",
    "                            yolo_ds.generate_yaml_file(\n",
    "                                root_abs_path=Path(CHANGE_ME_TO_YOUR_LOCAL_DIR), path_map['MODEL_NAME']),\n",
    "                                dest_abs_path=path_map['FTCNN_DS_MODEL'] / 'config',\n",
    "                            )\n",
    "                        except Exception as e:\n",
    "                            # Append the error message and remove the created files\n",
    "                            errors.append(f\"{path_map['MODEL_NAME']}: {e}\")\n",
    "                            shutil.rmtree(path_map['FTCNN_DS_MODEL'])\n",
    "                            shutil.rmtree(path_map['FTCNN_MODEL'])\n",
    "         \n",
    "                        # Update the pbar and update counter\n",
    "                        root_pbar.update()\n",
    "                        updates += 1\n",
    "\n",
    "root_pbar.set_description(f\"Dataset completed with {len(errors)} errors.\")\n",
    "root_pbar.refresh()\n",
    "root_pbar.close()\n",
    "\n",
    "if len(errors) > 0:\n",
    "    print(\"The following errors occurred:\\n\", \"\\n\".join(errors), file=sys.stderr)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BLANK\n",
    "yolo_ds.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
